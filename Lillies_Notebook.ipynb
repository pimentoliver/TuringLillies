{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d7d7e8",
   "metadata": {},
   "source": [
    "## A metaversal traveller's guide to interdimensional foraging and general plant use\n",
    "### 19019545 - Oliver Wood - o.wood0120191@arts.ac.uk - NLP for the Creative Industries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e4270e",
   "metadata": {},
   "source": [
    "Hello, wanderer. You may think you know where you are going - the map is here, you coordinates are stated. But do you know what lies there? Do you know what is needed to aid you along the way, and where to find it?\n",
    "\n",
    "I didn't think so. That is why I watch this portal - witches before and after me have watched it for millenia. You are going to Terra - no one mentions how strange a place it is. What you need and what you encounter is unlike any other. There, organisms grow from the ground beneath your feet. They are vivid, ranging in size and season and form. These organisms are one of the primary communities of the planet: they are so embedded in the ecosystem there that all other species use and interact with them.\n",
    "\n",
    "These organisms are strange allies, and even once consumed, they live on in terrestrial bodies through micro-organisms and bodily process. \n",
    "\n",
    "Our neighbors, humans, have spent a great deal of time documenting these organisms, their nature and properties. Luckily, we have a program to decode their documentation and make use of it ourselves, on treacherous journeys such as yours... \n",
    "\n",
    "Each one has specific properties: medicinal, edible, poisonous (which can also be quite useful), textile, environment-building - their uses are vast and frequently unexpected. Imagine biting into a long fruit, dug from the ground, bright orange in hue - to improve your eyesight and fuel your body? Can you imagine living your life in an box made of their thick, decaying corpses? Sleeping on beds of their shredded leaves, adorning your form in their woven threads? The way our neighbors interact with these forms is unfathomably strange. We are most grateful for their documentation - the information gathered by humans is of great use to any who moves from computational space to disorganized, strange, Terra. As your body is translated to the new space, so are your needs and abilities. You, too, will become dependent on these organisms. \n",
    "\n",
    "Every wanderer is different - we each need ten species to survive the journey. I can see that your **Flower Handbook** is empty - as I said, you do not truly know where you are going.\n",
    "\n",
    "No mind. Sit with me, child, we'll find the knowledge that you need and bind it together for your journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we're using two different text generation models\n",
    "#to create a 'handbook' of new plant species with pseudoscientific information about them.\n",
    "#It's fun to imagine this as an interdimensional traveller's toolbook however, this project has many applications\n",
    "#this can also be used, with varying datasets and models, to identify trends of online misinformation\n",
    "#surrounding biology, herbalism and relationships to food."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "291175e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61f1704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install datasets\n",
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a72bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install textgen model\n",
    "!pip install textgenrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34460f5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load in textgenrnn model for generating flower names\n",
    "#this model is easily accessible, fairly customizable and is computationally efficient\n",
    "#ideal for something like name generation\n",
    "\n",
    "import textgenrnn \n",
    "textgen = textgenrnn.textgenrnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f74415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install graphcore's gpt2 model - this one is computationally very efficient\n",
    "#and fine-tuned on a dataset of wikipedia entries\n",
    "#ideal for generating the kind of formal, pseudoscientific text we are looking for\n",
    "\n",
    "#code from model page on HuggingFace - link in citations cell\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Graphcore/gpt2-wikitext-103\")\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"Graphcore/gpt2-wikitext-103\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a55e4f",
   "metadata": {},
   "source": [
    "### Calling on the information collected by humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a718f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in flower names dataset\n",
    "\n",
    "flower_names = []\n",
    "\n",
    "f = open(\"flowers.csv\")\n",
    "\n",
    "for i in f:\n",
    "    #seperate text\n",
    "    line = i.rstrip().split(',')\n",
    "    flower_names.append(line)\n",
    "    \n",
    "#convert 2d list to 1d for simple processing\n",
    "flower_names = list(np.concatenate(flower_names).flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a52ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flower_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d817cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the textgen model\n",
    "\n",
    "textgen.reset() #Reset the model to avoid overfitting / overlapping\n",
    "\n",
    "textgen.train_on_texts(flower_names, num_epochs=5,  gen_epochs=5, train_size=0.5, dropout=0.2)\n",
    "\n",
    "#Using the parameters I found to be most effective for desired creative results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766f66d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating 125 new flower names and saving to .txt file\n",
    "textgen.generate_to_file('flower_names.txt', n=125, temperature=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7aa34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in and format the generated names\n",
    "\n",
    "gen_names = []\n",
    "\n",
    "with open('flower_names.txt') as t:\n",
    "    l = t.readlines()\n",
    "    for i in l:\n",
    "        #formatting text\n",
    "        i = i.strip()\n",
    "        i = re.sub(r\"[^a-zA-Z0-9]+\", ' ', i)\n",
    "        #append to list\n",
    "        gen_names.append(i)\n",
    "    #removing any duplicates by creating a set and converting back to list\n",
    "    gen_names = list(set(gen_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c48c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f004863",
   "metadata": {},
   "source": [
    "### Which 10 species of these strange creatures will aid you? Here, we'll call on them by generating input prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5fed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding some contextual information for our model. \n",
    "#these can be changed according to creative directions\n",
    "prompt2_options = [\"flower\", \"blossom\", \"weed\", \"plant\", \"tree\", \"bush\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12656175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompting pseudoscientific, educational or explanatory text\n",
    "#these can also be changed if so desired\n",
    "prompt3_options = [\"is an edible species of plant generally found growing in\", \"is an herbal species, favoured by foragers. It is frequently found in areas with\",\n",
    "                  \"is a floral species which blooms in\", \"is a seasonal wild edible found primarily in\", \n",
    "                   \"is a medicinal flower typically found in\", \"is a wild plant widely used for\", \"is a wildflower well-loved for it's sweet smell, typically found in\",\n",
    "                  \"is an herbal flower found in areas with\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abbaf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "\n",
    "for p in range (0,10):\n",
    "    prompt1 = random.choice(gen_names)\n",
    "    prompt2 = random.choice(prompt2_options)\n",
    "    prompt3 = random.choice(prompt3_options)\n",
    "    p = prompt1 + \" \" + prompt2 + \" \" + prompt3 + \" \"\n",
    "    prompts.append(p)\n",
    "prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0440ae",
   "metadata": {},
   "source": [
    "### Now, wanderer, we can fill our handbook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8182eccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate pseudoscientific/pseudo-educational text from prompts\n",
    "\n",
    "generator = pipeline(\"text-generation\",model=\"Graphcore/gpt2-wikitext-103\")\n",
    "\n",
    "handbook = []\n",
    "\n",
    "#writing our generations to our handbook\n",
    "#update max_length if you'd like to know more or less\n",
    "\n",
    "for p in prompts:\n",
    "    with open('flower_handbook.txt', 'a') as flower:\n",
    "        bud = generator(p, num_return_sequences=1, max_length=275)\n",
    "        blossom = str(bud)\n",
    "        \n",
    "        #formatting text\n",
    "        \n",
    "        blossom = blossom.replace(\"\\n\",\" \")                            \n",
    "        blossom = blossom.replace(\"generated_text\",\" \")\n",
    "        \n",
    "        #removing some tricky delimeters and their contained headings that come through \n",
    "        #due to being trained on wikipedia raw text\n",
    "        #such as '== History ==' or '//n Composition //n'\n",
    "        \n",
    "        #label the delimeters so we can locate them\n",
    "        i = \"=\"\n",
    "        f = \"\\\\n\"\n",
    "        \n",
    "        #iterate the text, remove delimeters and the text inside of them\n",
    "        #removes the delimeters in each different text generation, as they appear\n",
    "        \n",
    "        blossom = ' '.join(y.strip() for y in blossom.split(i)[::2])\n",
    "        blossom = ' '.join(x.strip() for x in blossom.split(f)[::2])\n",
    "        \n",
    "        #using regex to remove any other extraneous characters\n",
    "        \n",
    "        blossom = re.sub('[^.,a-zA-Z0-9 \\n\\.]', '', blossom)\n",
    "        blossom = blossom.strip()\n",
    "        \n",
    "        flower.write(blossom + \"\\n\")\n",
    "        handbook.append(blossom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b82240e",
   "metadata": {},
   "source": [
    "### Your handbook is complete, friend. You can take it with you, but have a look here too..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22284e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "handbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e41dcc",
   "metadata": {},
   "source": [
    "### citations and credit\n",
    "\n",
    "This notebook was made using the teaching, and some notebook content, from NLP Week 5.2.1\n",
    "\n",
    "I also referred to the Hugging Face Transformers tutorial - https://huggingface.co/course/en/chapter0/1\n",
    "\n",
    "The models I used are:\n",
    "\n",
    "textgenrnn by minimaxir (Max Woolf) on gitHub\n",
    "https://github.com/minimaxir/textgenrnn\n",
    "\n",
    "gpt-2 trained on wikitext by Optimum Graphcore on HuggingFace\n",
    "https://huggingface.co/Graphcore/gpt2-wikitext-103\n",
    "\n",
    "The dataset I used is:\n",
    "\n",
    "Flowers by BloomPop on gitHub\n",
    "https://github.com/Bloompop/Flowers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
